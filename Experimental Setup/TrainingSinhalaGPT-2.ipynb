{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyPCI837eBviKZJivC7No+xK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!pip install transformers datasets\n","!pip install torch\n","!pip install accelerate -u"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1gmkZSo6tFG","executionInfo":{"status":"ok","timestamp":1730535454842,"user_tz":-330,"elapsed":3910,"user":{"displayName":"Athulya Weerakoon","userId":"11711806329291214071"}},"outputId":"0ce2cb5f-f11f-4a3b-a3dd-342cb030b6ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","\n","Usage:   \n","  pip3 install [options] <requirement specifier> [package-index-options] ...\n","  pip3 install [options] -r <requirements file> [package-index-options] ...\n","  pip3 install [options] [-e] <vcs project url> ...\n","  pip3 install [options] [-e] <local project path> ...\n","  pip3 install [options] <archive url/path> ...\n","\n","no such option: -u\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Ni3EGN2630O","executionInfo":{"status":"ok","timestamp":1730535457208,"user_tz":-330,"elapsed":2371,"user":{"displayName":"Athulya Weerakoon","userId":"11711806329291214071"}},"outputId":"5dd39f06-98db-44bf-e543-6bffbbe62bb0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n","from datasets import load_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjqK8so97YLM","outputId":"d1a70b35-19bd-4ccf-8404-5aebe2ba023d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["\n","# Load the dataset\n","print(\"Loading dataset...\")\n","dataset = load_dataset(\"0xAIT/SIDAC\", split='train')\n","print(f\"Dataset loaded with {len(dataset)} examples.\")\n"],"metadata":{"id":"TY4uEMfO7ZeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the tokenizer and model\n","print(\"Loading GPT-2 tokenizer and model...\")\n","model_name = \"gpt2\"  # You can also use \"distilgpt2\" for a smaller option\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","print(\"Tokenizer and model loaded.\")"],"metadata":{"id":"KYFYWCgb7azN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize the dataset\n","print(\"Tokenizing dataset...\")\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], truncation=True)\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","print(\"Dataset tokenized.\")"],"metadata":{"id":"pv2Lh8E47cDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the first few tokenized examples\n","print(\"Sample tokenized example:\", tokenized_datasets[0])"],"metadata":{"id":"le1XfoDg7d7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up training arguments\n","print(\"Setting up training arguments...\")\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",  # Directory to save the model\n","    per_device_train_batch_size=4,  # Adjust based on your GPU memory\n","    num_train_epochs=3,  # Number of training epochs\n","    save_steps=10_000,  # Save model every 10,000 steps\n","    save_total_limit=2,  # Keep only the last 2 models\n","    logging_dir='./logs',  # Directory for storing logs\n","    logging_steps=500,  # Log every 500 steps\n","    evaluation_strategy=\"steps\",  # Evaluate during training\n","    eval_steps=500,  # Evaluate every 500 steps\n",")"],"metadata":{"id":"0LUCIdcf7gE4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a Trainer instance\n","print(\"Creating Trainer instance...\")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,  # Adjust based on your dataset\n",")"],"metadata":{"id":"cEdD2foo7htd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start training\n","print(\"Starting training...\")\n","trainer.train()\n","print(\"Training completed.\")\n"],"metadata":{"id":"4dNtRRmd7i4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model\n","print(\"Saving the model...\")\n","trainer.save_model(\"/content/drive/MyDrive/LLM_Tasks/ChatBot/GPT-2 model/fine_tuned_gpt2\")\n","print(\"Model saved successfully.\")"],"metadata":{"id":"YZbA3qs_7j2T"},"execution_count":null,"outputs":[]}]}